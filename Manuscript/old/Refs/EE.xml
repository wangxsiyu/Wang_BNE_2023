<?xml version="1.0" encoding="UTF-8"?><xml><records><record><database name="EE.enl" path="EE.enl">EE.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Mehlhorn, Katja</author><author>Newell, Ben R.</author><author>Todd, Peter M.</author><author>Lee, Michael D.</author><author>Morgan, Kate</author><author>Braithwaite, Victoria A.</author><author>Hausmann, Daniel</author><author>Fiedler, Klaus</author><author>Gonzalez, Cleotilde</author></authors></contributors><titles><title>Unpacking the exploration-exploitation tradeoff: A synthesis of human and animal literatures</title><secondary-title>Decision</secondary-title></titles><periodical><full-title>Decision</full-title></periodical><keywords><keyword>Decision making</keyword><keyword>Decision theory</keyword><keyword>Exploration- exploitation tradeoff</keyword><keyword>Foraging</keyword><keyword>Learning</keyword></keywords><dates><year>2015</year></dates><electronic-resource-num>10.1037/dec0000033</electronic-resource-num><urls/><abstract>Many decisions in the lives of animals and humans require a fine balance between the exploration of different options and the exploitation of their rewards. Do you buy the advertised car, or do you test drive different models? Do you continue feeding from the current patch of flowers, or do you fly offto another one? Do you marry your current partner, or try your luck with someone else? The balance required in these situations is commonly referred to as the exploration- exploitation tradeoff. It features prominently in a wide range of research traditions, including learning, foraging, and decision making literatures. Here, we integrate findings from these and other often-isolated literatures in order to gain a better understanding of the possible tradeoffs between exploration and exploitation, and we propose new theoretical insights that might guide future research. Specifically, we explore how potential tradeoffs depend on (a) the conceptualization of exploration and exploitation; (b) the influencing environmental, social, and individual factors; (c) the scale at which exploration and exploitation are considered; (d) the relationship and types of transitions between the 2 behaviors; and (e) the goals of the decision maker. We conclude that exploration and exploitation are best conceptualized as points on a continuum, and that the extent to which an agent's behavior can be interpreted as exploratory or exploitative depends upon the level of abstraction at which it is considered.</abstract></record><record><database name="EE.enl" path="EE.enl">EE.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Cinotti, Francois</author><author>Fresno, Virginie</author><author>Aklil, Nassim</author><author>Coutureau, Etienne</author><author>Girard, Benoit</author><author>Marchand, Alain</author><author>Khamassi, Mehdi</author></authors></contributors><titles><title>Dopamine regulates the exploration-exploitation trade-off in rats</title><secondary-title>bioRxiv</secondary-title></titles><periodical><full-title>bioRxiv</full-title></periodical><keywords/><dates><year>2018</year></dates><electronic-resource-num>10.1101/482802</electronic-resource-num><urls/><abstract>In a volatile environment where rewards are uncertain, successful performance requires a delicate balance between exploitation of the best option and exploration of alternative choices. It has theoretically been proposed that dopamine controls this exploration-exploitation trade-off, specifically that the higher the level of tonic dopamine, the more exploitation is favored. We demonstrate here that there is a formal relationship between the rescaling of dopamine positive reward prediction errors and the exploration-exploitation trade-off in simple non-stationary multi-armed bandit tasks. We further show in rats performing such a task that systemically antagonizing dopamine receptors greatly increases the number of random choices without affecting learning capacities. Simulations and comparison of a set of different computational models (an extended Q-learning model, a directed exploration model, and a meta-learning model) fitted on each individual confirm that, independently of the model, decreasing dopaminergic activity does not affect learning rate but is equivalent to an increase in exploration rate. This study shows that dopamine could adapt the exploration-exploitation trade-off in decision making when facing changing environmental contingencies.</abstract></record><record><database name="EE.enl" path="EE.enl">EE.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Hw, Stats-</author></authors></contributors><titles><title>No 主観的健康感を中心とした在宅高齢者における 健康関連指標に関する共分散構造分析Title</title><secondary-title>Problem Set 2</secondary-title></titles><periodical><full-title>Problem Set 2</full-title></periodical><pages>2019</pages><volume>23</volume><issue>3</issue><keywords/><dates><year>2019</year></dates><isbn>6103544947</isbn><urls><pdf-urls><url>internal-pdf://Koralek, Costa - 2019 - Sustained Dopaminergic Plateaus and Noradrenergic Depressions Bias Transitions into Exploitative Behavioral Stat.pdf</url></pdf-urls></urls></record><record><database name="EE.enl" path="EE.enl">EE.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Jackson, Brian J.</author><author>Fatima, Gusti Lulu</author><author>Oh, Sujean</author><author>Gire, David H.</author></authors></contributors><titles><title>Many Paths to the Same Goal: Balancing Exploration and Exploitation during Probabilistic Route Planning</title><secondary-title>eNeuro</secondary-title></titles><periodical><full-title>eNeuro</full-title></periodical><pages>1-11</pages><volume>7</volume><issue>3</issue><keywords><keyword>Bayesian</keyword><keyword>foraging</keyword><keyword>navigation</keyword></keywords><dates><year>2020</year></dates><accession-num>32414790</accession-num><electronic-resource-num>10.1523/ENEURO.0536-19.2020</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Jackson et al. - 2020 - Many Paths to the Same Goal Balancing Exploration and Exploitation during Probabilistic Route Planning - eNeuro.pdf</url></pdf-urls></urls><abstract>During self-guided behaviors, animals identify constraints of the problems they face and adaptively employ appropriate strategies (Marsh, 2002). In the case of foraging, animals must balance sensory-guided exploration of an environment with memory-guided exploitation of known resource locations. Here, we show that animals adaptively shift cognitive resources between sensory and memory systems during foraging to optimize route planning under uncertainty. We demonstrate this using a new, laboratory-based discovery method to define the strategies used to solve a difficult route optimization scenario, the probabilistic &quot;traveling salesman&quot; problem (Raman and Gill, 2017; Fuentes et al., 2018; Mukherjee et al., 2019). Using this system, we precisely manipulated the strength of prior information as well as the complexity of the problem. We find that rats are capable of efficiently solving this route-planning problem, even under conditions with unreliable prior information and a large space of possible solutions. Through analysis of animals' trajectories, we show that they shift the balance between exploiting known locations and searching for new locations of rewards based on the predictability of reward locations. When compared with a Bayesian search, we found that animal performance is consistent with an approach that adaptively allocates cognitive resources between sensory processing and memory, enhancing sensory acuity and reducing memory load under conditions in which prior information is unreliable. Our findings establish new approaches to understand neural substrates of natural behavior as well as the rational development of biologically inspired approaches for complex real-world optimization.</abstract></record><record><database name="EE.enl" path="EE.enl">EE.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Laskowski, C. S.</author><author>Williams, R. J.</author><author>Martens, K. M.</author><author>Gruber, A. J.</author><author>Fisher, K. G.</author><author>Euston, D. R.</author></authors></contributors><titles><title>The role of the medial prefrontal cortex in updating reward value and avoiding perseveration</title><secondary-title>Behavioural Brain Research</secondary-title></titles><periodical><full-title>Behavioural Brain Research</full-title></periodical><pages>52-63</pages><volume>306</volume><keywords><keyword>Decision making</keyword><keyword>Exploration</keyword><keyword>Prefrontal cortex</keyword><keyword>Reinforcement learning</keyword><keyword>Reward</keyword><keyword>Value</keyword></keywords><dates><year>2016</year></dates><publisher>Elsevier B.V.</publisher><electronic-resource-num>10.1016/j.bbr.2016.03.007</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Laskowski et al. - 2016 - The role of the medial prefrontal cortex in updating reward value and avoiding perseveration - Behavioural Bra.pdf</url></pdf-urls><web-urls><url>http://dx.doi.org/10.1016/j.bbr.2016.03.007</url></web-urls></urls><abstract>The medial prefrontal cortex (mPFC) plays a major role in goal-directed behaviours, but it is unclear whether it plays a role in breaking away from a high-value reward in order to explore for better options. To address this question, we designed a novel 3-arm Bandit Task in which rats were required to choose one of three potential reward arms, each of which was associated with a different amount of food reward and time-out punishment. After a variable number of choice trials the reward locations were shuffled and animals had to disengage from the now devalued arm and explore the other options in order to optimise payout. Lesion and control groups' behaviours on the task were then analysed by fitting data with a reinforcement learning model. As expected, lesioned animals obtained less reward overall due to an inability to flexibly adapt their behaviours after a change in reward location. However, modelling results showed that lesioned animals were no more likely to explore than control animals. We also discovered that all animals showed a strong preference for certain maze arms, at the expense of reward. This tendency was exacerbated in the lesioned animals, with the strongest effects seen in a subset of animals with damage to dorsal mPFC. The results confirm a role for mPFC in goal-directed behaviours but suggest that rats rely on other areas to resolve the explore-exploit dilemma.</abstract></record><record><database name="EE.enl" path="EE.enl">EE.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Monk, Christopher T.</author><author>Barbier, Matthieu</author><author>Romanczuk, Pawel</author><author>Watson, James R.</author><author>Alós, Josep</author><author>Nakayama, Shinnosuke</author><author>Rubenstein, Daniel I.</author><author>Levin, Simon A.</author><author>Arlinghaus, Robert</author></authors></contributors><titles><title>How ecology shapes exploitation: a framework to predict the behavioural response of human and animal foragers along exploration–exploitation trade-offs</title><secondary-title>Ecology Letters</secondary-title></titles><periodical><full-title>Ecology Letters</full-title></periodical><pages>779-793</pages><volume>21</volume><issue>6</issue><keywords><keyword>Conflict</keyword><keyword>consumer-resource</keyword><keyword>cooperation</keyword><keyword>fish and fisheries</keyword><keyword>governance</keyword><keyword>human behaviour</keyword><keyword>predator–prey</keyword><keyword>social-ecological system</keyword><keyword>sustainability</keyword></keywords><dates><year>2018</year></dates><accession-num>29611278</accession-num><electronic-resource-num>10.1111/ele.12949</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Monk et al. - 2018 - How ecology shapes exploitation a framework to predict the behavioural response of human and animal foragers alon.pdf</url></pdf-urls></urls><abstract>Understanding how humans and other animals behave in response to changes in their environments is vital for predicting population dynamics and the trajectory of coupled social-ecological systems. Here, we present a novel framework for identifying emergent social behaviours in foragers (including humans engaged in fishing or hunting) in predator–prey contexts based on the exploration difficulty and exploitation potential of a renewable natural resource. A qualitative framework is introduced that predicts when foragers should behave territorially, search collectively, act independently or switch among these states. To validate it, we derived quantitative predictions from two models of different structure: a generic mathematical model, and a lattice-based evolutionary model emphasising exploitation and exclusion costs. These models independently identified that the exploration difficulty and exploitation potential of the natural resource controls the social behaviour of resource exploiters. Our theoretical predictions were finally compared to a diverse set of empirical cases focusing on fisheries and aquatic organisms across a range of taxa, substantiating the framework's predictions. Understanding social behaviour for given social-ecological characteristics has important implications, particularly for the design of governance structures and regulations to move exploited systems, such as fisheries, towards sustainability. Our framework provides concrete steps in this direction.</abstract></record><record><database name="EE.enl" path="EE.enl">EE.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Beeler, Jeff A.</author><author>Daw, Nathaniel</author><author>Frazier, Cristianne R.M.</author><author>Zhuang, Xiaoxi</author></authors></contributors><titles><title>Tonic dopamine modulates exploitation of reward learning</title><secondary-title>Frontiers in Behavioral Neuroscience</secondary-title></titles><periodical><full-title>Frontiers in Behavioral Neuroscience</full-title></periodical><pages>1-14</pages><volume>4</volume><issue>NOV</issue><keywords><keyword>Behavioral flexibility</keyword><keyword>DAT knock-down</keyword><keyword>Dopamine</keyword><keyword>Environmental adaptation</keyword><keyword>Explore-exploit</keyword><keyword>Reinforcement learning</keyword></keywords><dates><year>2010</year></dates><electronic-resource-num>10.3389/fnbeh.2010.00170</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Beeler et al. - 2010 - Tonic dopamine modulates exploitation of reward learning - Frontiers in Behavioral Neuroscience.pdf</url></pdf-urls></urls><abstract>The impact of dopamine on adaptive behavior in a naturalistic environment is largely unexamined. Experimental work suggests that phasic dopamine is central to reinforcement learning whereas tonic dopamine may modulate performance without altering learning per se; however, this idea has not been developed formally or integrated with computational models of dopamine function. We quantitatively evaluate the role of tonic dopamine in these functions by studying the behavior of hyperdopaminergic DAT knockdown mice in an instrumental task in a seminaturalistic homecage environment. In this &quot;closed economy&quot; paradigm, subjects earn all of their food by pressing either of two levers, but the relative cost for food on each lever shifts frequently. Compared to wild-type mice, hyperdopaminergic mice allocate more lever presses on high-cost levers, thus working harder to earn a given amount of food and maintain their body weight. However, both groups show a similarly quick reaction to shifts in lever cost, suggesting that the hyperdominergic mice are not slower at detecting changes, as with a learning deficit. We fit the lever choice data using reinforcement learning models to assess the distinction between acquisition and expression the models formalize. In these analyses, hyperdopaminergic mice displayed normal learning from recent reward history but diminished capacity to exploit this learning: a reduced coupling between choice and reward history. These data suggest that dopamine modulates the degree to which prior learning biases action selection and consequently alters the expression of learned, motivated behavior. © 2010 Beeler, Daw, Frazier and Zhuang.</abstract></record><record><database name="EE.enl" path="EE.enl">EE.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Braz, Barbara Y.</author><author>Galinañes, Gregorio L.</author><author>Taravini, Irene R.E.</author><author>Belforte, Juan E.</author><author>Murer, M. Gustavo</author></authors></contributors><titles><title>Altered Corticostriatal Connectivity and Exploration/Exploitation Imbalance Emerge as Intermediate Phenotypes for a Neonatal Dopamine Dysfunction</title><secondary-title>Neuropsychopharmacology</secondary-title></titles><periodical><full-title>Neuropsychopharmacology</full-title></periodical><pages>2576-2587</pages><volume>40</volume><issue>11</issue><keywords/><dates><year>2015</year></dates><electronic-resource-num>10.1038/npp.2015.104</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Braz et al. - 2015 - Altered Corticostriatal Connectivity and ExplorationExploitation Imbalance Emerge as Intermediate Phenotypes for a.pdf</url></pdf-urls></urls><abstract>Findings showing that neonatal lesions of the forebrain dopaminergic system in rodents lead to juvenile locomotor hyperactivity and learning deficits have been taken as evidence of face validity for the attention deficit hyperactivity disorder. However, the core cognitive and physiological intermediate phenotypes underlying this rodent syndrome remain unknown. Here we show that early postnatal dopaminergic lesions cause long-lasting deficits in exploitation of shelter, social and nutritional resources, and an imbalanced exploratory behavior, where nondirected local exploration is exacerbated, whereas sophisticated search behaviors involving sequences of goal directed actions are degraded. Importantly, some behavioral deficits do not diminish after adolescence but instead worsen or mutate, particularly those related to the exploration of wide and spatially complex environments. The in vivo electrophysiological recordings and morphological reconstructions of striatal medium spiny neurons reveal corticostriatal alterations associated to the behavioral phenotype. More specifically, an attenuation of corticostriatal functional connectivity, affecting medial prefrontal inputs more markedly than cingulate and motor inputs, is accompanied by a contraction of the dendritic arbor of striatal projection neurons in this animal model. Thus, dopaminergic neurons are essential during postnatal development for the functional and structural maturation of corticostriatal connections. From a bottom-up viewpoint, our findings suggest that neuropsychiatric conditions presumably linked to developmental alterations of the dopaminergic system should be evaluated for deficits in foraging decision making, alterations in the recruitment of corticostriatal circuits during foraging tasks, and structural disorganization of the frontostriatal connections.</abstract></record><record><database name="EE.enl" path="EE.enl">EE.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Cinotti, François</author><author>Fresno, Virginie</author><author>Aklil, Nassim</author><author>Coutureau, Etienne</author><author>Girard, Benoît</author><author>Marchand, Alain R.</author><author>Khamassi, Mehdi</author></authors></contributors><titles><title>Dopamine blockade impairs the exploration-exploitation trade-off in rats</title><secondary-title>Scientific Reports</secondary-title></titles><periodical><full-title>Scientific Reports</full-title></periodical><pages>1-14</pages><volume>9</volume><issue>1</issue><keywords/><dates><year>2019</year></dates><isbn>4159801943</isbn><accession-num>31043685</accession-num><electronic-resource-num>10.1038/s41598-019-43245-z</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Cinotti et al. - 2019 - Dopamine blockade impairs the exploration-exploitation trade-off in rats - j.pdf</url></pdf-urls></urls><abstract>In a volatile environment where rewards are uncertain, successful performance requires a delicate balance between exploitation of the best option and exploration of alternative choices. It has theoretically been proposed that dopamine contributes to the control of this exploration-exploitation trade-off, specifically that the higher the level of tonic dopamine, the more exploitation is favored. We demonstrate here that there is a formal relationship between the rescaling of dopamine positive reward prediction errors and the exploration-exploitation trade-off in simple non-stationary multi-armed bandit tasks. We further show in rats performing such a task that systemically antagonizing dopamine receptors greatly increases the number of random choices without affecting learning capacities. Simulations and comparison of a set of different computational models (an extended Q-learning model, a directed exploration model, and a meta-learning model) fitted on each individual confirm that, independently of the model, decreasing dopaminergic activity does not affect learning rate but is equivalent to an increase in random exploration rate. This study shows that dopamine could adapt the exploration-exploitation trade-off in decision-making when facing changing environmental contingencies.</abstract></record><record><database name="EE.enl" path="EE.enl">EE.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Verharen, Jeroen P.H.</author><author>den Ouden, Hanneke E.M.</author><author>Adan, Roger A.H.</author><author>Vanderschuren, Louk J.M.J.</author></authors></contributors><titles><title>Modulation of value-based decision making behavior by subregions of the rat prefrontal cortex</title><secondary-title>Psychopharmacology</secondary-title></titles><periodical><full-title>Psychopharmacology</full-title></periodical><pages>1267-1280</pages><volume>237</volume><issue>5</issue><keywords><keyword>Behavioral modeling</keyword><keyword>Decision-making</keyword><keyword>Prefrontal cortex</keyword><keyword>Punishment</keyword><keyword>Rats</keyword><keyword>Reinforcement learning</keyword><keyword>Reward</keyword><keyword>Value</keyword></keywords><dates><year>2020</year></dates><publisher>Psychopharmacology</publisher><accession-num>32025777</accession-num><electronic-resource-num>10.1007/s00213-020-05454-7</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Verharen et al. - 2020 - Modulation of value-based decision making behavior by subregions of the rat prefrontal cortex - Psychopharmacol.pdf</url></pdf-urls></urls><abstract>Rationale: During value-based decision-making, organisms make choices on the basis of reward expectations, which have been formed during prior action-outcome learning. Although it is known that neuronal manipulations of different subregions of the rat prefrontal cortex (PFC) have qualitatively different effects on behavioral tasks involving value-based decision-making, it is unclear how these regions contribute to the underlying component processes. Objectives: Assessing how different regions of the rodent PFC contribute to component processes of value-based decision-making behavior, including reward (or positive feedback) learning, punishment (or negative feedback) learning, response persistence, and exploration versus exploitation. Methods: We performed behavioral modeling of data of rats in a probabilistic reversal learning task after pharmacological inactivation of five PFC subregions, to assess how inactivation of these different regions affected the structure of responding of animals in the task. Results: Our results show reductions in reward and punishment learning after PFC subregion inactivation. The prelimbic, infralimbic, lateral orbital, and medial orbital PFC particularly contributed to punishment learning, and the prelimbic and lateral orbital PFC to reward learning. In addition, response persistence depended on the infralimbic and medial orbital PFC. As a result, pharmacological inactivation of the infralimbic and lateral orbitofrontal cortex reduced the number of reversals achieved, whereas inactivation of the prelimbic and medial orbitofrontal cortex decreased the number of rewards obtained. Finally, using simulated data, we explain discrepancies with a previous study and demonstrate complex, interacting relationships between conventional measures of probabilistic reversal learning performance, such as win-stay/lose-switch behavior, and component processes of value-based decision-making. Conclusions: Together, our data suggest that distinct components of value-based learning and decision-making are generated in medial and orbital PFC regions, displaying functional specialization and overlap, with a prominent role of large parts of the PFC in negative feedback processing.</abstract></record><record><database name="EE.enl" path="EE.enl">EE.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Koralek, Aaron C.</author><author>Costa, Rui M.</author></authors></contributors><titles><title>Sustained Dopaminergic Plateaus and Noradrenergic Depressions Bias Transitions into Exploitative Behavioral States</title><secondary-title>bioRxiv</secondary-title></titles><periodical><full-title>bioRxiv</full-title></periodical><keywords/><dates><year>2019</year></dates><electronic-resource-num>10.1101/822650</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Koralek, Costa - 2019 - Sustained Dopaminergic Plateaus and Noradrenergic Depressions Bias Transitions into Exploitative Behavioral Stat.pdf</url></pdf-urls></urls><abstract>We are constantly faced with the trade-off between exploiting past actions with known outcomes and exploring novel actions whose outcomes may be better. The balance between exploitation and exploration has been hypothesized to rely on multiple neuromodulator systems, namely dopaminergic neurons of the substantia nigra pars compacta (SNc) and noradrenergic neurons of the locus coeruleus (LC). However, little is known about the dynamics of these neuromodulator systems during exploitative and exploratory states, or how they interact. We developed a novel behavioral paradigm to capture exploitative and exploratory behavioral states, and imaged calcium dynamics in genetically-identified dopaminergic SNc neurons and noradrenergic LC neurons during the transitions between these states. We found dichotomous changes in sustained activity in SNc and LC during exploitative bouts of action-reward, with SNc showing higher and LC showing lower sustained activity. Exploitative states were also marked by a lengthening of positive SNc response plateaus and negative LC response depressions, as well as hysteretic dynamics in SNc networks. Chemogenetic enhancement of dopaminergic and noradrenergic excitability favored exploitative and exploratory states, respectively. Together, these data suggest that opponent changes in dopaminergic and noradrenergic activity states modulate the transitions between exploitative and exploratory behavioral states, with important implications for downstream circuit dynamics.</abstract></record><record><database name="EE.enl" path="EE.enl">EE.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Parker, Nathan F.</author><author>Cameron, Courtney M.</author><author>Taliaferro, Joshua P.</author><author>Lee, Junuk</author><author>Choi, Jung Yoon</author><author>Davidson, Thomas J.</author><author>Daw, Nathaniel D.</author><author>Witten, Ilana B.</author></authors></contributors><titles><title>Reward and choice encoding in terminals of midbrain dopamine neurons depends on striatal target</title><secondary-title>Nature Neuroscience</secondary-title></titles><periodical><full-title>Nature Neuroscience</full-title></periodical><pages>845-854</pages><volume>19</volume><issue>6</issue><keywords/><dates><year>2016</year></dates><electronic-resource-num>10.1038/nn.4287</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Parker et al. - 2016 - Reward and choice encoding in terminals of midbrain dopamine neurons depends on striatal target - Nature Neurosci.pdf</url></pdf-urls></urls><abstract>Dopaminergic (DA) neurons in the midbrain provide rich topographic innervation of the striatum and are central to learning and to generating actions. Despite the importance of this DA innervation, it remains unclear whether and how DA neurons are specialized on the basis of the location of their striatal target. Thus, we sought to compare the function of subpopulations of DA neurons that target distinct striatal subregions in the context of an instrumental reversal learning task. We identified key differences in the encoding of reward and choice in dopamine terminals in dorsal versus ventral striatum: DA terminals in ventral striatum responded more strongly to reward consumption and reward-predicting cues, whereas DA terminals in dorsomedial striatum responded more strongly to contralateral choices. In both cases the terminals encoded a reward prediction error. Our results suggest that the DA modulation of the striatum is spatially organized to support the specialized function of the targeted subregion.</abstract></record><record><database name="EE.enl" path="EE.enl">EE.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Nissen, Henry W.</author></authors></contributors><titles><title>A Study of Exploratory Behavior in the White Rat by Means of the Obstruction Method</title><secondary-title>Pedagogical Seminary and Journal of Genetic Psychology</secondary-title></titles><periodical><full-title>Pedagogical Seminary and Journal of Genetic Psychology</full-title></periodical><pages>361-376</pages><volume>37</volume><issue>3</issue><keywords/><dates><year>1930</year></dates><electronic-resource-num>10.1080/08856559.1930.9944162</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Nissen - 1930 - A Study of Exploratory Behavior in the White Rat by Means of the Obstruction Method - Pedagogical Seminary and Journal o.pdf</url></pdf-urls></urls></record></records></xml>
